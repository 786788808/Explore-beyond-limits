#### 目录
- 一. 研究背景与目的
- 二. 数据探索
- 三. 数据清洗
- 四. 建模分析

### 一. 研究背景与目的：  
在UCI数据集里找到一个关于品酒的数据集，数据行包含各种酿酒成分以及专家对该酒的评分。   
数据下载地址：http://www3.dsi.uminho.pt/pcortez/wine/   
数据集包含白葡萄酒数据集，本篇选择白葡萄酒数据集：包含4898行，12列数据。都是数值型数据，很适合做回归分析。        
探寻影响白葡萄酒质量因素，哪些因素的影响比较大，哪些因素的影响比较小，是否存在可忽略的因素。是否可以给这些因素排优先级，给酿酒师提供一些建议。    

### 二. 数据探索：  
```
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import scale
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LassoCV
from sklearn.metrics import mean_squared_error
plt.rcParams["font.sans-serif"] = ["SimHei"]  # 正常显示中文标签
plt.rcParams["axes.unicode_minus"] = False   # 正常显示负号
plt.style.use('ggplot')
pd.set_option('display.max_columns', None)

wine_data = pd.read_csv(r'E:\……\data\winequality\winequality-white.csv', sep=';')
print((wine_data.head(5)))
print(wine_data.info())
print(wine_data.quality.unique())
print('重复值个数:', wine_data.duplicated().sum())
print(wine_data.describe())
print(wine_data.quality.value_counts())
col = wine_data.columns.to_list()
print(col)
# 箱线图
plt.figure(figsize=(11, 7))
for i in range(12):
    plt.subplot(2, 6, i+1)
    sns.boxplot(col[i], data=wine_data, orient='v', width=0.4, color='#0099CC')
    plt.ylabel(col[i])
plt.suptitle('各特征分布箱线图')
# 微调图的细节，left整体距离左边的距离，wspace子图之间的距离，top整体距离顶部的距离
plt.subplots_adjust(left=0.1, wspace=0.7, top=0.9)
plt.show()
# 直方图
plt.figure(figsize=(11, 7))
for i in range(12):
    plt.subplot(3, 4, i+1)
    plt.hist(col[i], data=wine_data, bins=110, color='#0099CC')
    plt.xlabel(col[i])
    plt.ylabel('Frequency')
plt.suptitle('各特征分布直方图')
# 微调图的细节，left整体距离左边的距离，wspace子图之间的距离，top整体距离顶部的距离
plt.subplots_adjust(left=0.1, wspace=0.7, hspace=0.5, top=0.9)
plt.show()
print('——————————偏度:——————————\n', wine_data.skew().sort_values(ascending=False))  # 偏度
print('=='*30)
print('——————————峰度：——————————\n', wine_data.kurt().sort_values(ascending=False))  # 峰度
```
#### (2.1) 自变量与因变量
自变量：'fixed acidity'非挥发性酸, 'volatile acidity'挥发性酸度, 'citric acid'柠檬酸, 'residual sugar'残糖, 'chlorides'氯化物, 'free sulfur dioxide'游离二氧化硫, 'total sulfur dioxide'总二氧化硫, 'density'密度,'pH'酸碱性, 'sulphates'硫酸盐, 'alcohol'酒精    
因变量：'quality' 质量分  
下面分别是箱线图与直方图：  
![](https://ftp.bmp.ovh/imgs/2020/12/615eeb1be28e8fe4.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/8782f072a765e88a.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/8a4bd52f95233d85.png)
![](https://ftp.bmp.ovh/imgs/2020/12/98f2943617506238.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/297af7b553e05754.png)  
可以看到：      
(1) 各特征值的范围差别大，有的特征值范围在\[0,0.35]，有的特征值范围在\[0,500]。回归算法里用到MSE作为评判建模效果，下面需要将各特征标准化处理，消除量纲的影响。      
(2) 从箱线图看到，部分变量存在较多异常值。但是基于这些是测量的数据，暂定是正确的。      
(3) 数据的偏度全部大于0，说明数据全部右偏，部分特征值存在较大的影响值。 右偏前5：chlorides > volatile acidity > free sulfur dioxide > citric acid> residual sugar。pH和total sulfur dioxide偏度最小。    
(4) 除了酒精特征，其余特征都呈现尖峰分布。尖峰前5:chlorides > free sulfur dioxide > density > citric acid > volatile acidity。total sulfur dioxide和pH峰度较小。    
(5) qualty质量分有3-9分，主要集中于6 5 7这三个分数，占比分别为45%、30%、18%。评分很高的9分和很低的3分共计占比不足1%，主要中等这部分占比较高(93%)，所以找到关键因素，提高酒的品质，对酿酒人来说很重要。   
#### (2.2) 缺失值情况
```
print(wine_data.isnull().sum())
```
数据都是数值型数据，没有缺失值。  
![](https://ftp.bmp.ovh/imgs/2020/11/60ae5eb564bd390c.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/615545519fe12927.png)
#### (2.3) 变量线性关系
```
corr = wine_data.corr()
mask = np.zeros_like(corr, dtype=np.bool)
mask[np.triu_indices_from(mask)] = True
sns.heatmap(corr, annot=True, mask=mask, linewidths=0.1, linecolor='white', vmin=-1, vmax=1)
plt.show()
```
![](https://ftp.bmp.ovh/imgs/2020/12/6164802974beabd0.png)   
从热力图看到：  
(1) 酒的品质跟酒精含量、密度的线性相关关系较强，酒精含量越高，口感评分越高。密度越高，口感评分越低。    
(2) 密度与剩余糖分的相关系数为0.84，与酒精的相关系数为-0.78。存在多重共线性。但是考虑到密度与酒精含量对口感评分的影响，先不删除任何特征。
### 三. 数据清洗&建模分析：
#### (3.1) 划分训练集、测试集与标准化处理：  
```
# 先划分训练集测试集，再进行标准化，以防止提前泄露测试集数据  
X = wine_data.iloc[:, 0:11]
Y = wine_data.loc[:, 'quality']
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=1000)
# print(X)
# print(Y)
x_train = scale(X_train)
x_test = scale(X_test)
```
#### (3.2) 一般线性回归模型：  
```
print('1.一般线性回归模型：\n')
print('=='*20)
LR = LinearRegression()
LR_1 = LR.fit(x_train, Y_train)
print('截距：', LR_1.intercept_)
print('回归系数：\n', LR_1.coef_)
LR_1_pred = LR_1.predict(x_test)
Coef_LR1 = pd.DataFrame(LR_1.coef_, index=col[0:11], columns=['回归系数'])
print(Coef_LR1.sort_values(by='回归系数', ascending=False))
print('测试集均方误差: ',  mean_squared_error(Y_test, LR_1_pred))
```
输出结果：    
![](https://ftp.bmp.ovh/imgs/2020/12/1d6d712dc7704a84.png)  
![](https://ftp.bmp.ovh/imgs/2020/12/2ffe085285b3dd9a.png)  
(1) 截距是5.88，各特征系数如上图。  
(2) 其中，residual sugar残糖和alcohol酒精含量对提高口感起重要作用。  
(3) 考虑到变量间的线性关系，考虑加入惩罚项。分别做lasso套索回归和ridge岭回归，看哪种模型效果比较好。       
>
#### (3.3) Lasso惩罚性线性回归：
```
print('2.Lasso回归模型：\n')
print('=='*20)
Ridge_1 = LassoCV(cv=10).fit(x_train, Y_train)
plt.plot()
plt.plot(Ridge_1.alphas_, Ridge_1.mse_path_, linestyle=':', label='均方误差')
plt.plot(Ridge_1.alphas_, Ridge_1.mse_path_.mean(axis=-1), label='十折均方误差均值', linewidth=2.5)
plt.axvline(Ridge_1.alpha_, linestyle='dashed', label='最佳α值')  # 用于画竖线
plt.semilogx()
ax = plt.gca()
ax.invert_xaxis()
plt.title('十折交叉验证对应 MSE 表现')
plt.xlabel('α值')
plt.ylabel('均方误差MSE')
plt.show()
print('截距：', Ridge_1.intercept_)
coef_Lasso = pd.DataFrame(Ridge_1.coef_, index=col[0:11], columns=['回归系数'])
print('回归系数：\n', coef_Lasso.sort_values(by='回归系数', ascending=False))
print('惩罚系数alpha:', Ridge_1.alpha_)
print('最小的均方误差:', min(Ridge_1.mse_path_.mean(axis=-1)))
y2_pred = Ridge_1.predict(x_test)
print('测试集均方误差：', mean_squared_error(Y_test, y2_pred))
```
输出结果：    
![](https://ftp.bmp.ovh/imgs/2020/12/c87a7bf5a67d638c.png)    
![](https://ftp.bmp.ovh/imgs/2020/12/1a6654251afeff0a.png)    
![](https://ftp.bmp.ovh/imgs/2020/12/a05a89c935501bcb.png)    
(1) 截距是5.88，惩罚系数是0.0054，回归系数如上图。   
(2) 其中，alcohol酒精含量和residual sugar残糖对提高口感评分有比较重要的影响，volatile acidity挥发性酸度和density密度会拉低口感评分。   
(3) Lasso模型也将fixed acidity固定酸度和citric acid柠檬酸的系数变为0。   
(4) 在测试集上的均方误差为0.58，整体表现不错。   
>
#### (3.3) Ridge惩罚性线性回归：
```
print('3.Ridge回归模型：\n')
print('=='*20)
alps = [i for i in range(500)]
# alps = [0.0001,0.001,0.1,1,10,20,50,55,60,70,100,150,1000]
Ridge_1 = RidgeCV(alphas=alps, cv=10).fit(x_train, Y_train)
print('截距：', Ridge_1.intercept_)  # 截距
coef_Lasso = pd.DataFrame(Ridge_1.coef_, index=col[0:11], columns=['回归系数'])  # 回归系数
print('回归系数：\n', coef_Lasso.sort_values(by='回归系数', ascending=False))
print('惩罚系数alpha:', Ridge_1.alpha_)  # 给出最优alpha值
y3_pred = Ridge_1.predict(x_test)
print('测试集均方误差：', mean_squared_error(Y_test, y3_pred))
```
输出结果：    
![](https://ftp.bmp.ovh/imgs/2020/12/2132160fb20dc12c.png)
(1) 截距是5.88，惩罚系数是53，回归系数如上图。   
(2) 其中，alcohol酒精含量和residual sugar残糖对提高口感评分依然排前两位，volatile acidity挥发性酸度和density密度同样是拉低口感评分的头两位。   
(3) Ridge模型里fixed acidity固定酸度和citric acid柠檬酸的系数被压缩到很小，分别是0.016和0.003。   
(4) 在测试集上的均方误差也是0.58，整体表现不错。   
(5) 在三个模型里，chlorides氯化物、total sulfur dioxide总二氧化硫、volatile acidity挥发性酸度和density密度的回归系数都是负数。在酿酒的时候可以尝试减少前三类物质的比例，从而降低白葡萄酒的密度，提高酒的纯度。
(6) 根据二八定理，企业可将更多精力放在研究口感更佳的白葡萄酒上。现有的数据集里，5 6 7分的酒占93%，中等酒更普遍存在。这类酒一般定位是走量款，要是想在市场占有更大的市场份额，酿造8、9分的酒，是一条有效途径。酒精含量和残糖是两个很关键的因素，应重点调配这两类物质的比例。
>
### 四. 总结
(1) 三个模型在测试集里的表现都很相近，MSE都是0.58。在实际应用中，更建议采用带惩罚的回归模型，而由于lasso会使模型稀疏，应用Ridge模型更具实际意义。  
(2) 优化模型可考虑更高阶模型，加入关键因素的平方、相乘，有可能可以降低均方误差，提高模型的泛化能力。  
(3) 咨询行业专家，加入更多因素，能让模型更具实际指导意义。  
